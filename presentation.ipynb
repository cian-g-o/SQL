{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "bXbTE1tM6scC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e9VAK8sF524",
        "outputId": "bc6ad4d4-8496-4f1d-e3b9-41c829ba8a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mysqlclient in /usr/local/lib/python3.10/dist-packages (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json \n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "!pip install mysqlclient"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**API KEYS AND CONNECTION DETAILS**"
      ],
      "metadata": {
        "id": "2xNuJLGfqxFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#api key \n",
        "# cian.o.jr@outlook.com = API_KEY\n",
        "# cobrie31@lion.lmu.edu = API_KEY\n",
        "api_key='API_KEY'\n",
        "#api endpoint\n",
        "api_url = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'\n",
        "#headers\n",
        "headers = {'Content-type': 'application/json'}\n",
        "#The following are all monthly indices\n",
        "  # National Employment Data : CEU0800000003\n",
        "  # Job Openings and Turnover : JTU110099000000000HIL\n",
        "  # CPI (Consumer Price Index) : CUUR0000SA0L1E\n",
        "  # PPI (Producer Price Index) : PCU22112222112241\n",
        "  # Consumer Expenditure : CXUMENBOYSLB0101M\n",
        "#params\n",
        "data = json.dumps({\"seriesid\": ['CEU0800000003'],\"startyear\":\"2012\", \"endyear\":\"2020\"})"
      ],
      "metadata": {
        "id": "nXCirmOtGxaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**THE FOLLOWING 5 CODE SCRIPTS ARE FOR ECONOMIC INDICATORS FROM THE BUREAU OF LABOR STATISTICS.**\n",
        "\n",
        "**PULLS DATA FROM THEIR API, PUTS INTO DATA FRAME, THEN INJECTS INTO DATABASE**\n",
        "\n"
      ],
      "metadata": {
        "id": "TS8oM8-7prfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for National Employment Data - BLS\n",
        "\n",
        "# National Employment Data : CEU0800000003\n",
        "data = json.dumps({\"seriesid\": ['CEU0800000003'],\"startyear\":\"2012\", \"endyear\":\"2022\"})\n",
        "api_request = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
        "api_response = json.loads(api_request.text)\n",
        "econ_data = api_response['Results']['series']\n",
        "\n",
        "#Initialize Dictionary\n",
        "economic_data={\n",
        "    'year':[],\n",
        "    'period':[],\n",
        "    'periodName':[],\n",
        "    'value':[]\n",
        "    }\n",
        "\n",
        "# loop through data  \n",
        "for data in econ_data:\n",
        "    for d in data['data']:\n",
        "        economic_data['year'].append(d['year'])\n",
        "        economic_data['period'].append(d['period'])\n",
        "        economic_data['periodName'].append(d['periodName'])\n",
        "        economic_data['value'].append(d['value'])\n",
        "# turn it into a data frame\n",
        "df = pd.DataFrame(economic_data)\n",
        "# define engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "# insert into database\n",
        "df.to_sql('National_Employment_Data', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "Q4tT97eNV-EW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5ec643-240a-4424-f22c-fa1ccc16e387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Job Openings and Turnover - BLS\n",
        "\n",
        "# Job Openings and Turnover : JTU110099000000000HIL\n",
        "data = json.dumps({\"seriesid\": ['JTU110099000000000HIL'],\"startyear\":\"2012\", \"endyear\":\"2022\"})\n",
        "api_request = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
        "api_response = json.loads(api_request.text)\n",
        "econ_data = api_response['Results']['series']\n",
        "\n",
        "#Initialize Dictionary\n",
        "economic_data={\n",
        "    'year':[],\n",
        "    'period':[],\n",
        "    'periodName':[],\n",
        "    'value':[]\n",
        "    }\n",
        "    \n",
        "# loop through data  \n",
        "for data in econ_data:\n",
        "    for d in data['data']:\n",
        "        economic_data['year'].append(d['year'])\n",
        "        economic_data['period'].append(d['period'])\n",
        "        economic_data['periodName'].append(d['periodName'])\n",
        "        economic_data['value'].append(d['value'])\n",
        "# turn it into a data frame\n",
        "df = pd.DataFrame(economic_data)\n",
        "# define engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "# insert into database\n",
        "df.to_sql('Job_Openings_and_Turnover', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "OKaFd2HhjULK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2244b823-e4f1-42a2-aee8-c12ff4756591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for CPI - BLS\n",
        "\n",
        "# CPI (Consumer Price Index) : CUUR0000SA0L1E\n",
        "data = json.dumps({\"seriesid\": ['CUUR0000SA0L1E'],\"startyear\":\"2012\", \"endyear\":\"2022\"})\n",
        "api_request = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
        "api_response = json.loads(api_request.text)\n",
        "econ_data = api_response['Results']['series']\n",
        "\n",
        "#Initialize Dictionary\n",
        "economic_data={\n",
        "    'year':[],\n",
        "    'period':[],\n",
        "    'periodName':[],\n",
        "    'value':[]\n",
        "    }\n",
        "    \n",
        "# loop through data  \n",
        "for data in econ_data:\n",
        "    for d in data['data']:\n",
        "        economic_data['year'].append(d['year'])\n",
        "        economic_data['period'].append(d['period'])\n",
        "        economic_data['periodName'].append(d['periodName'])\n",
        "        economic_data['value'].append(d['value'])\n",
        "# turn it into a data frame\n",
        "df = pd.DataFrame(economic_data)\n",
        "# define engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "# insert into database\n",
        "df.to_sql('CPI', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "-oEpt8BKjnkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c46b008-d8d7-4e35-b9fb-e9e453d18b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for PPI - BLS\n",
        "\n",
        "# PPI (Producer Price Index) : PCU22112222112241\n",
        "data = json.dumps({\"seriesid\": ['PCU22112222112241'],\"startyear\":\"2012\", \"endyear\":\"2022\"})\n",
        "api_request = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
        "api_response = json.loads(api_request.text)\n",
        "econ_data = api_response['Results']['series']\n",
        "\n",
        "#Initialize Dictionary\n",
        "economic_data={\n",
        "    'year':[],\n",
        "    'period':[],\n",
        "    'periodName':[],\n",
        "    'value':[]\n",
        "    }\n",
        "    \n",
        "# loop through data  \n",
        "for data in econ_data:\n",
        "    for d in data['data']:\n",
        "        economic_data['year'].append(d['year'])\n",
        "        economic_data['period'].append(d['period'])\n",
        "        economic_data['periodName'].append(d['periodName'])\n",
        "        economic_data['value'].append(d['value'])\n",
        "# turn it into a data frame\n",
        "df = pd.DataFrame(economic_data)\n",
        "# define engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "# insert into database\n",
        "df.to_sql('PPI', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "RtK8Nosfj7Q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ff0b3-dbb4-46fa-c656-31b93781d110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for Consumer Expenditure - BLS\n",
        "\n",
        "# Consumer Expenditure : CXUMENBOYSLB0101M\n",
        "data = json.dumps({\"seriesid\": ['CXUMENBOYSLB0101M'],\"startyear\":\"2012\", \"endyear\":\"2022\"})\n",
        "api_request = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
        "api_response = json.loads(api_request.text)\n",
        "econ_data = api_response['Results']['series']\n",
        "\n",
        "#Initialize Dictionary\n",
        "economic_data={\n",
        "    'year':[],\n",
        "    'period':[],\n",
        "    'periodName':[],\n",
        "    'value':[]\n",
        "    }\n",
        "# loop through data\n",
        "for data in econ_data:\n",
        "    for d in data['data']:\n",
        "        economic_data['year'].append(d['year'])\n",
        "        economic_data['period'].append(d['period'])\n",
        "        economic_data['periodName'].append(d['periodName'])\n",
        "        economic_data['value'].append(d['value'])\n",
        "# turn it into a data frame\n",
        "df = pd.DataFrame(economic_data)\n",
        "# define engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "# insert into database\n",
        "df.to_sql('Consumer_Expenditure', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "qeJw636dkNIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbc4100-af04-4aa8-8812-1360cbd9f1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THE FOLLOWING CODE SCRIPT IS FOR HOUSEHOLD INCOME DISTRIBUTION IN THE UNITED STATES FROM STATISTA**\n",
        "\n",
        "**THEY DID NOT HAVE AN API, SO I DOWNLOADED THEIR EXCEL, CLEANED IT UP, AND INJECTED IT INTO THE DATABASE**"
      ],
      "metadata": {
        "id": "AeeD1LFd7wO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Income Distribution Data from Statista\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(\"Statista_Median_Household_Income_Distribution.xlsx\", sheet_name=\"Data\")\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the import\n",
        "print(df.head())\n",
        "\n",
        "#defining engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "\n",
        "#inserting into database\n",
        "df.to_sql('Median_Income_Distribution', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "Ki8zs395q5IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THE FOLLOWING CODE SCRIPT IS FOR FOOD SPENDING BY DEMOGRAPHICS FROM THE NATIONAL LIBRARY OF MEDICINE**\n",
        "\n",
        "**THEY DID NOT HAVE AN API, SO I DOWNLOADED THEIR EXCEL, CLEANED IT UP, AND INJECTED IT INTO THE DATABASE**"
      ],
      "metadata": {
        "id": "eS0pURkg8F9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Food Spending by Age Data from National Library of Medicine\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(\"Food_Spending.xlsx\", sheet_name=\"Age\")\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the import\n",
        "print(df.head())\n",
        "\n",
        "#defining engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "\n",
        "#inserting into database\n",
        "df.to_sql('Food_Spending_By_Age', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "0jxhn40qcF1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Food Spending by Gender Data from National Library of Medicine\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(\"Food_Spending.xlsx\", sheet_name=\"Gender\")\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the import\n",
        "print(df.head())\n",
        "\n",
        "#defining engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "\n",
        "#inserting into database\n",
        "df.to_sql('Food_Spending_By_Gender', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "U7fF3NSxdhtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Food Spending by Ethnicity Data from National Library of Medicine\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(\"Food_Spending.xlsx\", sheet_name=\"Ethnicity\")\n",
        "\n",
        "# Print the first few rows of the DataFrame to verify the import\n",
        "print(df.head())\n",
        "\n",
        "#defining engine\n",
        "engine = create_engine('mysql://USERNAME:PASSWORD@HOST/DATABASE')\n",
        "\n",
        "#inserting into database\n",
        "df.to_sql('Food_Spending_By_Ethnicity', engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "1qoSn3rXdwzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALLATIONS AND EXTENSIONS**"
      ],
      "metadata": {
        "id": "jPnA45laxqTt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tHoQYYYd8pMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e0830c0-8b13-4d78-8635-598b4b3f9902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mysqlclient\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp310-cp310-linux_x86_64.whl size=108353 sha256=7d9c967ff8de99acbd4374f8d190bb14d00036707883c3d9dd98ec94feb8d69b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/34/ba/a769c165b01646816afdf9bf792e847ef149693fee432b6b65\n",
            "Successfully built mysqlclient\n",
            "Installing collected packages: mysqlclient\n",
            "Successfully installed mysqlclient-2.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython-sql in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: prettytable<1 in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (0.7.2)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (0.2.0)\n",
            "Requirement already satisfied: sqlalchemy>=0.6.7 in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (2.0.10)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (0.4.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (1.16.0)\n",
            "Requirement already satisfied: ipython>=1.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (7.34.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (3.0.38)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (67.7.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (0.1.6)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=1.0->ipython-sql) (5.7.1)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.6.7->ipython-sql) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=0.6.7->ipython-sql) (4.5.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.6)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SQLAlchemy==1.4.4\n",
            "  Downloading SQLAlchemy-1.4.4.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==1.4.4) (2.0.2)\n",
            "Building wheels for collected packages: SQLAlchemy\n",
            "  Building wheel for SQLAlchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.4.4-cp310-cp310-linux_x86_64.whl size=1513274 sha256=3cd3882d4cc91b8739f236a30427de7bad329a643faaa74b219ae86c5735ce1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c3/55/803261c43577195a922fd6aead99e6b4ed9be457dee35a1600\n",
            "Successfully built SQLAlchemy\n",
            "Installing collected packages: SQLAlchemy\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed SQLAlchemy-1.4.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sqlalchemy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%load_ext sql\n",
        "!pip install mysqlclient\n",
        "!pip install ipython-sql\n",
        "!pip install SQLAlchemy==1.4.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONNECTING TO DATABASE INSTANCE**"
      ],
      "metadata": {
        "id": "9z7gr-y6xu52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%sql mysql://USERNAME:PASSWORD@HOST/DATABASE"
      ],
      "metadata": {
        "id": "M08akYteCJ5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ed0c84-4648-41a5-b876-d5a4cd1d88d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n",
            "module 'sqlalchemy.util.compat' has no attribute 'TYPE_CHECKING'\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THE FOLLOWING CELLS ARE BASIC QUERIES TO CHECK ALL THE TABLES IN MY DATABASE AND ENSURE DATA QUALITY**"
      ],
      "metadata": {
        "id": "UeMlLPM9x6DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: DATA QUALITY CHECK FOR MONTHLY ECONOMIC DATA, MONTH OVER MONTH"
      ],
      "metadata": {
        "id": "N_hDQ-e20sCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT *\n",
        "FROM National_Employment_Data ned \n",
        "\tJOIN Consumer_Expenditure ce \n",
        "\t\tON ned.year = ce.year\n",
        "\tJOIN CPI c \n",
        "\t\tON c.year = ned.year\n",
        "\t\tAND c.period = ned.period\n",
        "\tJOIN Job_Openings_and_Turnover joat \n",
        "\t\tON joat.year = ned.year\n",
        "\t\tAND joat.period = ned.period\n",
        "\tJOIN PPI p \t\n",
        "\t\tON p.year = ned.year\n",
        "\t\tAND p.period = ned.period\t\n",
        "ORDER BY ned.year DESC, ned.period; "
      ],
      "metadata": {
        "id": "0Kk-TJKFv95j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a5b84b-4182-4aef-b6f0-f25ce1bb4c21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variable $DATABASE_URL not set, and no connect string given.\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Clean and full dataset. How has the economy been performing?*"
      ],
      "metadata": {
        "id": "y2riLZ5K_r_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: DATA QUALITY CHECK FOR ANNUAL ECONOMIC AND INCOME DISTRIBUTION DATA"
      ],
      "metadata": {
        "id": "vWdeS2Xl0tqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT *\n",
        "FROM Consumer_Expenditure ce \n",
        "\tJOIN Median_Income_Distribution mid2 \n",
        "\t\tON ce.year = mid2.year;"
      ],
      "metadata": {
        "id": "YtaUJka54PvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc76258a-4dd8-4945-d5c3-0adc1ac215e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variable $DATABASE_URL not set, and no connect string given.\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Clean and full dataset. How has income distribution changed for America and how can Walmart take advantage of it?*"
      ],
      "metadata": {
        "id": "TIQ-bC-jAYya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: DATA QUALITY CHECK FOR FOOD SPENDING DATA"
      ],
      "metadata": {
        "id": "PrHrthWU1g9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT *\n",
        "FROM Food_Spending_By_Age fsba;"
      ],
      "metadata": {
        "id": "zZbjMdqn4QMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97f50ec-af7c-4d4f-a2c7-c79c92ded6eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variable $DATABASE_URL not set, and no connect string given.\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Clean and full dataset. Which demographics spend the most on food at home?*"
      ],
      "metadata": {
        "id": "RlunvZokAdAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT *\n",
        "FROM Food_Spending_By_Ethnicity fsbe;"
      ],
      "metadata": {
        "id": "BWKJbAvz4czG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1781bfc6-2278-44bf-fcbb-d3af7c9fa681"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variable $DATABASE_URL not set, and no connect string given.\n",
            "Connection info needed in SQLAlchemy format, example:\n",
            "               postgresql://username:password@hostname/dbname\n",
            "               or an existing connection: dict_keys([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Clean and full dataset. Which demographics spend the most on food at home?*"
      ],
      "metadata": {
        "id": "NIZQ1C-lAd_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT *\n",
        "FROM Food_Spending_By_Gender fsbg;"
      ],
      "metadata": {
        "id": "Os6hU3wL4gN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Clean and full dataset. Which demographics spend the most on food at home?*"
      ],
      "metadata": {
        "id": "aMfpJOoHAe_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THE FOLLOWING CELLS ARE STILL EXPLORATORY AND ARE USED TO HELP ME DISCOVER INSIGHTS FOR THE SUPPLEMENTARY QUERIES**"
      ],
      "metadata": {
        "id": "Z2MtDEJXHySg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: FINDING AVERAGES OF FOOD AT HOME SPENDING"
      ],
      "metadata": {
        "id": "2pe6ZhIr1hXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH cte_food_spending_by_age AS (\n",
        "  SELECT \n",
        "    age,\n",
        "    percentage_of_respondents AS PercentOfGroup,\n",
        "    FAH_per_week_4_year_avg AS WeeklyAvg4Year,\n",
        "    percentage_of_respondents * FAH_per_week_4_year_avg / 100 AS WeeklyAvgTotalFAH4Year\n",
        "  FROM Food_Spending_By_Age\n",
        ")\n",
        "SELECT \n",
        "\tSUM(WeeklyAvgTotalFAH4Year) AS FAH_Average_Weekly_Spent_4_Year\n",
        "FROM cte_food_spending_by_age;"
      ],
      "metadata": {
        "id": "TdXFDpW3iliJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: I was interested to see what the average American spent on food at home, as food makes up around 60% of Walmart Inc.'s unit sales. Now that I know the average I plan to see which specific demogrpahics Walmart can prioritize and market to in order to maximize profit.*"
      ],
      "metadata": {
        "id": "uYHUrCKzwMC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: FINDING AVERAGE JOB OPENING & LABOR TURNOVER BY MONTH"
      ],
      "metadata": {
        "id": "yQUSq6nK1ht1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT \n",
        "\tperiodName AS month,\n",
        "\tAVG(value) AS Average_JOLT_per_Month\n",
        "FROM Job_Openings_and_Turnover joat \n",
        "GROUP BY period\n",
        "ORDER BY AVG(value);"
      ],
      "metadata": {
        "id": "PuiKRZmP4RBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: If Walmart were to expand I was curious when there are the most openings in the job market. Walmart would want to avoid these months as it would make hiring much more competitive. I plan to find the average so I can utilize this information better.*"
      ],
      "metadata": {
        "id": "zcSF4vMdxVFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY: FINDING OVERALL AVERAGE JOB OPENING & LABOR TURNOVER"
      ],
      "metadata": {
        "id": "1UhLKHToG7i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT \n",
        "    AVG(value) AS Average_JOLT\n",
        "FROM Job_Openings_and_Turnover"
      ],
      "metadata": {
        "id": "v-Q-RNvWG8B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insight: Like I said before, knowing when there are the most job openings during different parts of the year can help Walmart prioritize hiring times. Even if they choose not to expand with the combinations of this and the previous query, the company can focus avoid wasting hiring resources during the upswings in job openings.*"
      ],
      "metadata": {
        "id": "1ynfq7qOxxE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Primary Question: Based on the current economic indicators and trends, is this a good time for expansion currently?**\n",
        "\n",
        "Justification: The primary question I wanted to answer with all of this data analysis was whether or not it was a good time for Walmart to expand, either by location or product range. Although Walmart is relatively recession proof due to it's nature of providing low cost products, it would not be advisable to do so during an economic downturn.\n",
        "\n",
        "Features Used:\n",
        "- Group By\n",
        "- Join"
      ],
      "metadata": {
        "id": "xHM0UL171iID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT \n",
        "\tned.year, \n",
        "\tROUND(AVG(ned.value),2) AS Employment_Index,\n",
        "\tROUND(AVG(joat.value), 2) AS Job_Opening_Turnover_Index,\n",
        "\tROUND(AVG(c.value), 2) AS CPI_Index,\n",
        "\tROUND(AVG(p.value), 2) AS Producer_Price_Index,\n",
        "\tROUND(AVG(ce.value), 2) AS Consumer_Exp_Index\n",
        "FROM National_Employment_Data ned \n",
        "\tJOIN Consumer_Expenditure ce \n",
        "\t\tON ned.year = ce.year\n",
        "\tJOIN CPI c \n",
        "\t\tON c.year = ned.year\n",
        "\t\tAND c.period = ned.period\n",
        "\tJOIN Job_Openings_and_Turnover joat \n",
        "\t\tON joat.year = ned.year\n",
        "\t\tAND joat.period = ned.period\n",
        "\tJOIN PPI p \t\n",
        "\t\tON p.year = ned.year\n",
        "\t\tAND p.period = ned.period\t\n",
        "GROUP BY year\n",
        "ORDER BY year DESC; "
      ],
      "metadata": {
        "id": "BPcqJMOR4R9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insights: I used the economic indicators of a National Employment Index (aggregate of hours worked and wages thorugout US), a Job Openings and Labor Turnover Index (aggregate job openings, those who quit, and those who were fired), a Consumer and Producer Price Index (measurement of inflation), and a Consumer Exp Index (how much Americans were spending) to measure the health of the economy. From the results we can see that the Employment Index is still relatively strong, meaning people are still working a lot. Although the JOLT Index has not recovered to Pre-Covid Levels it still shows positive growth. Both of these trends point to a healthy economy. Conversely, the CPI and PPI tell us that inflation has risen a decent amount, but with the Fed raising interest rates to prevent a recession this should be of little worry. Most importantly, is that Consumer Expenditure has risen almost to Pre-Covid levels. People's perception of how the economy will do plays a huge role in how it actually does. If nobody's spending money and saving because they fear a crash, than that will lead to less economic activity and spiral. Altogether these indicators point to a healthy economy at least for the time being, and if Walmart wanted to expand this would be a great time to do so.*"
      ],
      "metadata": {
        "id": "5xIgXXzHu0Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Secondary Question: If Walmart were to expand it's number of locations, when would be the best time for it to do so? When would it have the least amount of competition?**\n",
        "\n",
        "Justification: Hiring and onboarding can cost a lot, especially for large stores such as Walmart and Sam's Club. By planning their expansions and hiring period during job opening lulls they can be much faster and efficient with their resources.\n",
        "\n",
        "Features Used:\n",
        "- Case\n",
        "- Subquery"
      ],
      "metadata": {
        "id": "QsWSY_fy2FQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT \n",
        "\tavg_jolt.periodName AS Month, \n",
        "\tavg_jolt.Average_JOLT_per_Month,\n",
        "\tCASE WHEN avg_jolt.Average_JOLT_per_MONTH < 27.366 THEN 'Good Time to Hire for New Location'\n",
        "\tELSE 'Not Good Time to Hire for New Location' \n",
        "\tEND AS 'Good Opening Month or Not'\n",
        "FROM (\n",
        "\t  SELECT \n",
        "\t  \tperiod,\n",
        "\t    periodName,\n",
        "\t    AVG(value) AS Average_JOLT_per_Month\n",
        "\t  FROM Job_Openings_and_Turnover\n",
        "\t  GROUP BY period\n",
        ") avg_jolt\n",
        "ORDER BY period;"
      ],
      "metadata": {
        "id": "iec0ElWI46lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insights: If Walmart Inc. decided to take my advice and expand, I thought it would be useful to figure out the best times of year to do so. Staffing a large supermarket is no easy feat and they would want to begin hiring when there is the least amount of competition. The data shows that the end of the year Nov and Dec would be the best times as they have the lowest JOLT indexes throughout the entire year. With a less competitive job market (from the employer side), Walmart Inc. will be able to choose from a larger pool of possible employees and hire more productive and dedicated members, eventually leading to overall efficiency improvements and more profit.*"
      ],
      "metadata": {
        "id": "-LzUymXlutzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Secondary Question: How has the landscape of American wealth distribution changed and what can we do to do stay ahead of the curve when it comes to product and price demand?**\n",
        "\n",
        "Justification: Because I think Walmart should expand I was curious if the consumer market has changed at all and if they should consider switching the products they provide, from cheaper to more high end.\n",
        "\n",
        "Features Used:\n",
        "- CTE"
      ],
      "metadata": {
        "id": "x90S_lmB1iym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH yearly_cpi AS (\n",
        "\tSELECT \n",
        "\t\tyear,\n",
        "\t\tAVG(value) AS Avg_value\n",
        "\tFROM CPI c \n",
        "\tGROUP BY year\n",
        ")\n",
        "SELECT \n",
        "\ty.year,\n",
        "\tROUND(less_than_15_000 + 15_000_to_24_999 + 25_000_to_34_999, 2) AS 0_to_34999,\n",
        "\tROUND(35_000_to_49_999 + 50_000_to_74_999 + 75_000_to_99_999, 2) AS 35000_to_99999,\n",
        " \tROUND(100_000_to_149_999 + 150_000_to_199_999 + 200_000_or_more, 2) AS 100000_or_more,\n",
        " \tROUND(Avg_value, 2) AS yearly_cpi\n",
        "FROM Median_Income_Distribution mid2\n",
        "  JOIN yearly_cpi y\n",
        "    ON y.year=mid2.year\n",
        "ORDER BY year DESC;"
      ],
      "metadata": {
        "id": "j_WwgZKR41Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insights: Initially when I ran this query I neglected to include the CPI (Index of how much goods cost for an average household), and the slight increases between the income brackets led me to believe that maybe they should reconsider their business model. However, if you account for the almost 20% increase in CPI over the last decade, in comparsion to the minute upward movement within the income brackets, it is abundantly clear that they shouldn't. Although there has certainly been an upward trend in income over the past 10 years it pales in comparison to inflation. This means there is much less purchasing power per dollar and overall most Americans are worse off now in terms of disposable income. Households will prioritize getting more bang for their buck, which plays perfectly into Walmart's business model. This leads me to recommend that Walmart Inc. should double down on it's business model and continue to offer very low cost products and brands. Possibly even dedicating more resources to Sam's Club to compete with Costco, maybe through initial discounts on memberships to attract customers.*"
      ],
      "metadata": {
        "id": "qtnhyl-0uy48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Secondary Question: Are there any demographics of Americans that spend more on food that we can cater to in order to increase customer loyalty and profit?**\n",
        "\n",
        "Justification: Walmart Inc. gains 60% of it's net sales from food and consumable products. As it is the largest category by volume, expanding our product lines to hold more desirable products to those who usually spend more will be very profitable and helpful in gaining more customers.\n",
        "\n",
        "Features Used:\n",
        "- View\n",
        "- Window"
      ],
      "metadata": {
        "id": "E7iD4mJm2F0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Age\n",
        "%%sql\n",
        "CREATE OR REPLACE VIEW FAH_above_Average_Age\n",
        "AS\n",
        "\tSELECT \n",
        "\t\tage,\n",
        "\t\tFAH_per_week_4_year_avg \n",
        "\tFROM Food_Spending_By_Age fsba\n",
        "\tWHERE FAH_per_week_4_year_avg > 91.8326;\n",
        "\n",
        "  SELECT \n",
        "\tage,\n",
        " \tROW_NUMBER () OVER (ORDER BY FAH_per_week_4_year_avg ASC) AS 'Row Number'\n",
        "  FROM FAH_above_Average_Age;"
      ],
      "metadata": {
        "id": "17EXeehl47dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ethnicity\n",
        "%%sql\n",
        "CREATE OR REPLACE VIEW FAH_above_Average_Ethnicity\n",
        "AS\n",
        "\tSELECT \n",
        "\t\tethnicity,\n",
        "\t\tFAH_per_week_4_year_avg \n",
        "\tFROM Food_Spending_By_Ethnicity fsba\n",
        "\tWHERE FAH_per_week_4_year_avg > 91.8326;\n",
        "\n",
        "  SELECT \n",
        "\tethnicity,\n",
        " \tROW_NUMBER () OVER (ORDER BY FAH_per_week_4_year_avg ASC) AS 'Row Number'\n",
        "  FROM FAH_above_Average_Ethnicity;"
      ],
      "metadata": {
        "id": "fFdzMRcXrLrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gender\n",
        "%%sql\n",
        "CREATE OR REPLACE VIEW FAH_above_Average_Gender\n",
        "AS\n",
        "\tSELECT \n",
        "\t\tgender,\n",
        "\t\tFAH_per_week_4_year_avg \n",
        "\tFROM Food_Spending_By_Gender fsba\n",
        "\tWHERE FAH_per_week_4_year_avg > 91.8326;\n",
        "\n",
        "  SELECT \n",
        "\tgender,\n",
        " \tROW_NUMBER () OVER (ORDER BY FAH_per_week_4_year_avg ASC) AS 'Row Number'\n",
        "FROM FAH_above_Average_Gender;"
      ],
      "metadata": {
        "id": "3lBWb-e2re1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insights: Since it makes up such a large amount of their inventory, and seems to be a big part of why customers shop there, I thought it would be best to see which demographics in America are more likely to spend on \"At-Home\" food. The first query shows us that is an older population that generally spends more on at home food, 31-45 tops the list, followed by 46-55 and lastly, 56-65. The second query shows that the ethnicities that spend the more than the average are Other(not African-American, Hispanic, or White) and White. The last query tells us which gender spends more on at home food, which is men. Walmart Inc. can go a multitude of ways with this information. I belive it should encompass expanding to include products that are more popular with these demographics or using more targeted marketing. When consumers realize they can find more of their favorite foods/consumables at Walmart that will build brand loyalty. By altering their most popular category to cater to those who are more likely to spend more they not only get more revenue from food, but by having more customers come in all of their categories will improve. I don't think solely focusing on these demographics would be a good strategy for the business, but a few extra niche products couldn't hurt."
      ],
      "metadata": {
        "id": "HTQQsrFMupJE"
      }
    }
  ]
}